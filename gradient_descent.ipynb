{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MID = 2\n",
    "gamma = 0.1  # Lower learning rate\n",
    "c = 0\n",
    "\n",
    "# Xavier initialization\n",
    "w1 = np.random.randn(1, MID) * np.sqrt(2 / 1)\n",
    "w2 = np.random.randn(MID, MID) * np.sqrt(2 / MID)\n",
    "w3 = np.random.randn(MID, MID) * np.sqrt(2 / MID)\n",
    "w4 = np.random.randn(MID, MID) * np.sqrt(2 / MID)\n",
    "w5 = np.random.randn(MID, 1) * np.sqrt(2 / MID)\n",
    "\n",
    "b1, b2, b3, b4, b5 = np.zeros((1, MID)), np.zeros((1, MID)), np.zeros((1, MID)), np.zeros((1, MID)), np.zeros((1, 1))\n",
    "\n",
    "relu = lambda x: np.maximum(0, x)\n",
    "relu_p = lambda x: np.where(x > 0, 1.0, 0.0)\n",
    "\n",
    "target = lambda x: 2**x\n",
    "\n",
    "def clip_gradient(grad, limit=1.0):\n",
    "    return np.clip(grad, -limit, limit)\n",
    "a0 = np.linspace(0, 13, 30).reshape(-1, 1)\n",
    "y = target(a0)\n",
    "while True:\n",
    "    c += 1\n",
    "   \n",
    "    # Forward pass\n",
    "    z1 = a0 @ w1 + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = a1 @ w2 + b2\n",
    "    a2 = relu(z2)\n",
    "    z3 = a2 @ w3 + b3\n",
    "    a3 = relu(z3)\n",
    "    z4 = a3 @ w4 + b4\n",
    "    a4 = relu(z4)\n",
    "    z5 = a4 @ w5 + b5\n",
    "    a5 = z5  # No ReLU on output\n",
    "\n",
    "    loss = np.mean((a5 - y) ** 2)\n",
    "\n",
    "    # Backpropagation\n",
    "    da5 = 2 * (a5 - y)\n",
    "    dz5 = da5\n",
    "    dw5 = a4.T @ dz5\n",
    "    db5 = np.sum(dz5, axis=0, keepdims=True)\n",
    "    w5 -= gamma * clip_gradient(dw5)\n",
    "    b5 -= gamma * clip_gradient(db5)\n",
    "\n",
    "    da4 = dz5 @ w5.T\n",
    "    dz4 = da4 * relu_p(z4)\n",
    "    dw4 = a3.T @ dz4\n",
    "    db4 = np.sum(dz4, axis=0, keepdims=True)\n",
    "    w4 -= gamma * clip_gradient(dw4)\n",
    "    b4 -= gamma * clip_gradient(db4)\n",
    "\n",
    "    da3 = dz4 @ w4.T\n",
    "    dz3 = da3 * relu_p(z3)\n",
    "    dw3 = a2.T @ dz3\n",
    "    db3 = np.sum(dz3, axis=0, keepdims=True)\n",
    "    w3 -= gamma * clip_gradient(dw3)\n",
    "    b3 -= gamma * clip_gradient(db3)\n",
    "\n",
    "    da2 = dz3 @ w3.T\n",
    "    dz2 = da2 * relu_p(z2)\n",
    "    dw2 = a1.T @ dz2\n",
    "    db2 = np.sum(dz2, axis=0, keepdims=True)\n",
    "    w2 -= gamma * clip_gradient(dw2)\n",
    "    b2 -= gamma * clip_gradient(db2)\n",
    "\n",
    "    da1 = dz2 @ w2.T\n",
    "    dz1 = da1 * relu_p(z1)\n",
    "    dw1 = a0.T @ dz1\n",
    "    db1 = np.sum(dz1, axis=0, keepdims=True)\n",
    "    w1 -= gamma * clip_gradient(dw1)\n",
    "    b1 -= gamma * clip_gradient(db1)\n",
    "\n",
    "    # Check for NaN\n",
    "    if np.isnan(loss):\n",
    "        print(\"Loss became NaN. Stopping training.\")\n",
    "        break\n",
    "\n",
    "    if c % 1000 == 0:\n",
    "        print(f\"Iteration {c}: Loss = {loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z1 = np.linspace(0, 13, 30).reshape(-1, 1) @ w1 + b1\n",
    "a1 = relu(z1)\n",
    "z2 = a1 @ w2 + b2\n",
    "a2 = relu(z2)\n",
    "z3 = a2 @ w3 + b3\n",
    "a3 = relu(z3)\n",
    "z4 = a3 @ w4 + b4\n",
    "a4 = relu(z4)\n",
    "z5 = a4 @ w5 + b5\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(0, 13, 30), z5)\n",
    "plt.plot(np.linspace(0, 13, 30), 2**np.linspace(0, 13, 30))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
